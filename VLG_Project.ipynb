{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10146,
     "status": "ok",
     "timestamp": 1656522723983,
     "user": {
      "displayName": "shreyansh jain",
      "userId": "15851526152066987878"
     },
     "user_tz": -330
    },
    "id": "FvNpbjMnEpZ8",
    "outputId": "d7e86a80-b443-491c-f886-d8e69ab30c34"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting nes-py==0.2.6\n",
      "  Using cached nes_py-0.2.6-cp37-cp37m-linux_x86_64.whl\n",
      "Requirement already satisfied: pyglet>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from nes-py==0.2.6) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from nes-py==0.2.6) (1.21.6)\n",
      "Requirement already satisfied: pygame>=1.9.3 in /usr/local/lib/python3.7/dist-packages (from nes-py==0.2.6) (2.1.2)\n",
      "Requirement already satisfied: gym>=0.10.5 in /usr/local/lib/python3.7/dist-packages (from nes-py==0.2.6) (0.17.3)\n",
      "Requirement already satisfied: tqdm>=4.19.5 in /usr/local/lib/python3.7/dist-packages (from nes-py==0.2.6) (4.64.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.10.5->nes-py==0.2.6) (1.3.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.10.5->nes-py==0.2.6) (1.4.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet>=1.3.2->nes-py==0.2.6) (0.16.0)\n",
      "Installing collected packages: nes-py\n",
      "  Attempting uninstall: nes-py\n",
      "    Found existing installation: nes-py 8.2.1\n",
      "    Uninstalling nes-py-8.2.1:\n",
      "      Successfully uninstalled nes-py-8.2.1\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gym-super-mario-bros 7.4.0 requires nes-py>=8.1.4, but you have nes-py 0.2.6 which is incompatible.\u001B[0m\n",
      "Successfully installed nes-py-0.2.6\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: gym-super-mario-bros in /usr/local/lib/python3.7/dist-packages (7.4.0)\n",
      "Collecting nes-py>=8.1.4\n",
      "  Using cached nes_py-8.2.1-cp37-cp37m-linux_x86_64.whl\n",
      "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros) (0.17.3)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.21.6)\n",
      "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (1.3.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (1.4.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.21,>=1.4.0->nes-py>=8.1.4->gym-super-mario-bros) (0.16.0)\n",
      "Installing collected packages: nes-py\n",
      "  Attempting uninstall: nes-py\n",
      "    Found existing installation: nes-py 0.2.6\n",
      "    Uninstalling nes-py-0.2.6:\n",
      "      Successfully uninstalled nes-py-0.2.6\n",
      "Successfully installed nes-py-8.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nes-py==0.2.6\n",
    "!pip install gym-super-mario-bros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3826,
     "status": "ok",
     "timestamp": 1656534471430,
     "user": {
      "displayName": "shreyansh jain",
      "userId": "15851526152066987878"
     },
     "user_tz": -330
    },
    "id": "X2y9wwJSFDbJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import pickle\n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY\n",
    "import gym\n",
    "import numpy as np\n",
    "import collections\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1656534471431,
     "user": {
      "displayName": "shreyansh jain",
      "userId": "15851526152066987878"
     },
     "user_tz": -330
    },
    "id": "0FI9MvNgF8Wk"
   },
   "outputs": [],
   "source": [
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "  def __init__(self, env=None, skip=4):\n",
    "      super(MaxAndSkipEnv, self).__init__(env)\n",
    "      self._obs_buffer = collections.deque(maxlen=2)\n",
    "      self._skip = skip\n",
    "\n",
    "  def step(self, action):\n",
    "    total_reward = 0.0\n",
    "    done = None\n",
    "    for _ in range(self._skip):\n",
    "      obs, reward, done, info = self.env.step(action)\n",
    "      self._obs_buffer.append(obs)\n",
    "      total_reward += reward\n",
    "      if done:\n",
    "        break\n",
    "    max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
    "    return max_frame, total_reward, done, info\n",
    "\n",
    "  def reset(self):\n",
    "    self._obs_buffer.clear()\n",
    "    obs = self.env.reset()\n",
    "    self._obs_buffer.append(obs)\n",
    "    return obs\n",
    "\n",
    "class ProcessFrame84(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Downsamples image to 84x84\n",
    "    Greyscales image\n",
    "\n",
    "    Returns numpy array\n",
    "    \"\"\"\n",
    "    def __init__(self, env=None):\n",
    "        super(ProcessFrame84, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return ProcessFrame84.process(obs)\n",
    "\n",
    "    @staticmethod\n",
    "    def process(frame):\n",
    "        if frame.size == 240 * 256 * 3:\n",
    "            img = np.reshape(frame, [240, 256, 3]).astype(np.float32)\n",
    "        else:\n",
    "            assert False, \"Unknown resolution.\"\n",
    "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
    "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
    "        x_t = resized_screen[18:102, :]\n",
    "        x_t = np.reshape(x_t, [84, 84, 1])\n",
    "        return x_t.astype(np.uint8)\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]),\n",
    "                                                dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    \"\"\"Normalize pixel values in frame --> 0 to 1\"\"\"\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "class BufferWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, n_steps, dtype=np.float32):\n",
    "        super(BufferWrapper, self).__init__(env)\n",
    "        self.dtype = dtype\n",
    "        old_space = env.observation_space\n",
    "        self.observation_space = gym.spaces.Box(old_space.low.repeat(n_steps, axis=0),\n",
    "                                                old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
    "\n",
    "    def reset(self):\n",
    "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
    "        return self.observation(self.env.reset())\n",
    "\n",
    "    def observation(self, observation):\n",
    "        self.buffer[:-1] = self.buffer[1:]\n",
    "        self.buffer[-1] = observation\n",
    "        return self.buffer\n",
    "\n",
    "def make_env(env):\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    env = ProcessFrame84(env)\n",
    "    env = ImageToPyTorch(env)\n",
    "    env = BufferWrapper(env, 4)\n",
    "    env = ScaledFloatFrame(env)\n",
    "    return JoypadSpace(env, RIGHT_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1656534471432,
     "user": {
      "displayName": "shreyansh jain",
      "userId": "15851526152066987878"
     },
     "user_tz": -330
    },
    "id": "U40_I7lbNDke"
   },
   "outputs": [],
   "source": [
    "def show_state(env, ep=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"Episode: %d %s\" % (ep, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 883,
     "status": "ok",
     "timestamp": 1656534472310,
     "user": {
      "displayName": "shreyansh jain",
      "userId": "15851526152066987878"
     },
     "user_tz": -330
    },
    "id": "IoOb58dJNJIz",
    "outputId": "0ac863fa-3fa2-45bc-9045-9bd85e5d3161"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.54509807, 0.54509807, 0.54509807, ..., 0.54509807,\n",
       "         0.54509807, 0.54509807],\n",
       "        [0.54509807, 0.54509807, 0.54509807, ..., 0.54509807,\n",
       "         0.54509807, 0.54509807],\n",
       "        [0.54509807, 0.54509807, 0.54509807, ..., 0.54509807,\n",
       "         0.54509807, 0.54509807],\n",
       "        ...,\n",
       "        [0.5647059 , 0.48235294, 0.4509804 , ..., 0.34901962,\n",
       "         0.5764706 , 0.3254902 ],\n",
       "        [0.43529412, 0.3764706 , 0.33333334, ..., 0.42745098,\n",
       "         0.49411765, 0.3254902 ],\n",
       "        [0.63529414, 0.5294118 , 0.44705883, ..., 0.44313726,\n",
       "         0.48235294, 0.28627452]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
    "env = make_env(env)  # Wraps the environment so that frames are grayscale\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1656534472310,
     "user": {
      "displayName": "shreyansh jain",
      "userId": "15851526152066987878"
     },
     "user_tz": -330
    },
    "id": "JFtTs-0RNYWX"
   },
   "outputs": [],
   "source": [
    "class Deep_Q_Learning(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(Deep_Q_Learning, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "    \n",
    "    def _get_conv_out(self, shape):\n",
    "        output = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(output.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "        return self.fc(conv_out)\n",
    "    \n",
    "\n",
    "class DQNAgent:\n",
    "\n",
    "    def __init__(self, state_space, action_space, max_mem, batch_size, gamma, lr,\n",
    "                 epsilon_greedy, epsilon_min, epsilon_decay, pretrained):\n",
    "\n",
    "        # Define DQN Layers\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.pretrained = pretrained\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "       \n",
    "        self.local_net = Deep_Q_Learning(state_space, action_space).to(self.device)\n",
    "        self.target_net = Deep_Q_Learning(state_space, action_space).to(self.device)\n",
    "            \n",
    "        if self.pretrained:\n",
    "            self.local_net.load_state_dict(torch.load(\"dq1.pt\", map_location=torch.device(self.device)))\n",
    "            self.target_net.load_state_dict(torch.load(\"dq2.pt\", map_location=torch.device(self.device)))\n",
    "                    \n",
    "        self.optimizer = torch.optim.Adam(self.local_net.parameters(), lr=lr)\n",
    "        self.copy = 5000  # Copy the local model weights into the target network every 5000 steps\n",
    "        self.step = 0\n",
    "\n",
    "        # Create memory\n",
    "        self.max_mem = max_mem\n",
    "        if self.pretrained:\n",
    "            #self.State_Memory = torch.load(\"State_Memory.pt\")\n",
    "            self.State_Memory = torch.zeros(max_mem, *self.state_space)\n",
    "            self.Action_Memory = torch.load(\"Action_Memory.pt\")\n",
    "            self.Reward_Memory = torch.load(\"Reward_Memory.pt\")\n",
    "            #self.State2_Memory = torch.load(\"State2_Memory.pt\")\n",
    "            self.State2_Memory = torch.zeros(max_mem, *self.state_space)\n",
    "            self.Done_Memory = torch.load(\"Done_Memory.pt\")\n",
    "            with open(\"ending_position.pkl\", 'rb') as f:\n",
    "                self.ending_position = pickle.load(f)\n",
    "            with open(\"num_in_queue.pkl\", 'rb') as f:\n",
    "                self.num_in_queue = pickle.load(f)\n",
    "        else:\n",
    "            self.State_Memory = torch.zeros(max_mem, *self.state_space)\n",
    "            self.Action_Memory = torch.zeros(max_mem, 1)\n",
    "            self.Reward_Memory = torch.zeros(max_mem, 1)\n",
    "            self.State2_Memory = torch.zeros(max_mem, *self.state_space)\n",
    "            self.Done_Memory = torch.zeros(max_mem, 1)\n",
    "            self.ending_position = 0\n",
    "            self.num_in_queue = 0\n",
    "        \n",
    "        self.mem_size = batch_size\n",
    "        \n",
    "        # Learning parameters\n",
    "        self.gamma = gamma\n",
    "        self.l1 = nn.SmoothL1Loss().to(self.device) # Also known as Huber loss\n",
    "        self.epsilon_greedy = epsilon_greedy\n",
    "        self.exploration_rate = epsilon_greedy\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "\n",
    "    def remember(self, state, action, reward, state2, done):\n",
    "        self.State_Memory[self.ending_position] = state.float()\n",
    "        self.Action_Memory[self.ending_position] = action.float()\n",
    "        self.Reward_Memory[self.ending_position] = reward.float()\n",
    "        self.State2_Memory[self.ending_position] = state2.float()\n",
    "        self.Done_Memory[self.ending_position] = done.float()\n",
    "        self.ending_position = (self.ending_position + 1) % self.max_mem  # FIFO tensor\n",
    "        self.num_in_queue = min(self.num_in_queue + 1, self.max_mem)\n",
    "        \n",
    "    def recall(self):\n",
    "        # Randomly sample 'batch size' experiences\n",
    "        idx = random.choices(range(self.num_in_queue), k=self.mem_size)\n",
    "        \n",
    "        STATE = self.State_Memory[idx]\n",
    "        ACTION = self.Action_Memory[idx]\n",
    "        REWARD = self.Reward_Memory[idx]\n",
    "        STATE2 = self.State2_Memory[idx]\n",
    "        DONE = self.Done_Memory[idx]\n",
    "        \n",
    "        return STATE, ACTION, REWARD, STATE2, DONE\n",
    "\n",
    "    def act(self, state):\n",
    "        # Epsilon-greedy action\n",
    "        \n",
    "        self.step += 1\n",
    "        if random.random() < self.exploration_rate:  \n",
    "            return torch.tensor([[random.randrange(self.action_space)]])\n",
    "\n",
    "        # Local net is used for the policy\n",
    "        return torch.argmax(self.local_net(state.to(self.device))).unsqueeze(0).unsqueeze(0).cpu()\n",
    "\n",
    "\n",
    "    def copy_model(self):\n",
    "        # Copy local net weights into target net\n",
    "        \n",
    "        self.target_net.load_state_dict(self.local_net.state_dict())\n",
    "    \n",
    "    def experience_replay(self):\n",
    "        \n",
    "        if self.step % self.copy == 0:\n",
    "            self.copy_model()\n",
    "\n",
    "        if self.mem_size > self.num_in_queue:\n",
    "            return\n",
    "\n",
    "        STATE, ACTION, REWARD, STATE2, DONE = self.recall()\n",
    "        STATE = STATE.to(self.device)\n",
    "        ACTION = ACTION.to(self.device)\n",
    "        REWARD = REWARD.to(self.device)\n",
    "        STATE2 = STATE2.to(self.device)\n",
    "        DONE = DONE.to(self.device)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "            # Double Q-Learning target is Q*(S, A) <- r + γ max_a Q_target(S', a)\n",
    "        target = REWARD + torch.mul((self.gamma * \n",
    "                                        self.target_net(STATE2).max(1).values.unsqueeze(1)), \n",
    "                                        1 - DONE)\n",
    "\n",
    "        current = self.local_net(STATE).gather(1, ACTION.long()) # Local net approximation of Q-value\n",
    "        \n",
    "        loss = self.l1(current, target)\n",
    "        loss.backward() # Compute gradients\n",
    "        self.optimizer.step() # Backpropagate error\n",
    "\n",
    "        self.exploration_rate *= self.epsilon_decay\n",
    "        \n",
    "        # Makes sure that exploration rate is always at least 'exploration min'\n",
    "        self.exploration_rate = max(self.exploration_rate, self.epsilon_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1656534472311,
     "user": {
      "displayName": "shreyansh jain",
      "userId": "15851526152066987878"
     },
     "user_tz": -330
    },
    "id": "1UHRpVQUUaIu"
   },
   "outputs": [],
   "source": [
    "def run(training_mode, pretrained):\n",
    "   \n",
    "    env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
    "    env = make_env(env)  # Wraps the environment so that frames are grayscale \n",
    "    observation_space = env.observation_space.shape\n",
    "    action_space = env.action_space.n\n",
    "    agent = DQNAgent(state_space=observation_space,\n",
    "                     action_space=action_space,\n",
    "                     max_mem=30000,\n",
    "                     batch_size=32,\n",
    "                     gamma=0.90,\n",
    "                     lr=0.00025,\n",
    "                     epsilon_greedy=1.0,\n",
    "                     epsilon_min=0.02,\n",
    "                     epsilon_decay=0.99,\n",
    "                     pretrained=pretrained)\n",
    "    \n",
    "    num_episodes = 10000\n",
    "    env.reset()\n",
    "    total_rewards = []\n",
    "    \n",
    "    for ep_num in tqdm(range(num_episodes)):\n",
    "        state = env.reset()\n",
    "        state = torch.Tensor(np.array([state]))\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        while True:\n",
    "            if not training_mode:\n",
    "                #show_state(env, ep_num)\n",
    "                pass\n",
    "            action = agent.act(state)\n",
    "            steps += 1\n",
    "            \n",
    "            state_next, reward, terminal, info = env.step(int(action[0]))\n",
    "            total_reward += reward\n",
    "            state_next = torch.Tensor(np.array([state_next]))\n",
    "            reward = torch.tensor(np.array([reward])).unsqueeze(0)\n",
    "            \n",
    "            terminal = torch.tensor([int(terminal)]).unsqueeze(0)\n",
    "            \n",
    "            if training_mode:\n",
    "                print(\"state\", state)\n",
    "                print(\"action\", action)\n",
    "                print(\"reward\", reward)\n",
    "                print(\"state_next\", state_next)\n",
    "                print(\"terminal\", terminal)\n",
    "                agent.remember(state, action, reward, state_next, terminal)\n",
    "                agent.experience_replay()\n",
    "            \n",
    "            state = state_next\n",
    "            if terminal:\n",
    "                break\n",
    "        \n",
    "        total_rewards.append(total_reward)\n",
    "\n",
    "        print(\"Total reward after episode {} is {}\".format(ep_num + 1, total_rewards[-1]))\n",
    "        num_episodes += 1      \n",
    "    \n",
    "    if training_mode:\n",
    "        with open(\"ending_position.pkl\", \"wb\") as f:\n",
    "            pickle.dump(agent.ending_position, f)\n",
    "        with open(\"num_in_queue.pkl\", \"wb\") as f:\n",
    "            pickle.dump(agent.num_in_queue, f)\n",
    "        with open(\"total_rewards.pkl\", \"wb\") as f:\n",
    "            pickle.dump(total_rewards, f)\n",
    "        \n",
    "        torch.save(agent.local_net.state_dict(), \"dq1.pt\")\n",
    "        torch.save(agent.target_net.state_dict(), \"dq2.pt\")\n",
    "        torch.save(agent.State_Memory,  \"State_Memory.pt\")\n",
    "        torch.save(agent.Action_Memory, \"Action_Memory.pt\")\n",
    "        torch.save(agent.Reward_Memory, \"Reward_Memory.pt\")\n",
    "        torch.save(agent.State2_Memory, \"State2_Memory.pt\")\n",
    "        torch.save(agent.Done_Memory,   \"Done_Memory.pt\")\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    if num_episodes > 500:\n",
    "        plt.title(\"Episodes trained vs. Average Rewards (per 500 eps)\")\n",
    "        plt.plot([0 for _ in range(500)] + \n",
    "                 np.convolve(total_rewards, np.ones((500,))/500, mode=\"valid\").tolist())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def give_agent(training_mode, pretrained):\n",
    "    env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
    "    env = make_env(env)  # Wraps the environment so that frames are grayscale\n",
    "    observation_space = env.observation_space.shape\n",
    "    action_space = env.action_space.n\n",
    "    agent = DQNAgent(state_space=observation_space,\n",
    "                     action_space=action_space,\n",
    "                     max_mem=30000,\n",
    "                     batch_size=32,\n",
    "                     gamma=0.90,\n",
    "                     lr=0.00025,\n",
    "                     epsilon_greedy=1.0,\n",
    "                     epsilon_min=0.02,\n",
    "                     epsilon_decay=0.99,\n",
    "                     pretrained=pretrained)\n",
    "    print(agent.Action_Memory.shape)\n",
    "    return env, agent"
   ],
   "metadata": {
    "id": "SagCLQM8yEjU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1656534472311,
     "user_tz": -330,
     "elapsed": 4,
     "user": {
      "displayName": "shreyansh jain",
      "userId": "15851526152066987878"
     }
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "envi, mario_agent = give_agent(False, True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3U_JSUI3yXly",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1656534490216,
     "user_tz": -330,
     "elapsed": 17909,
     "user": {
      "displayName": "shreyansh jain",
      "userId": "15851526152066987878"
     }
    },
    "outputId": "714497cd-6762-4e96-a09a-ea9c2628d97a"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([30000, 1])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "count = 0\n",
    "reward_counter = 0\n",
    "begin = 0\n",
    "max_reward = 0\n",
    "max_begin = 0\n",
    "max_end = 0\n",
    "num = 0\n",
    "for i in mario_agent.Done_Memory:\n",
    "  reward_counter += mario_agent.Reward_Memory[count].tolist()[0]\n",
    "  if i == torch.Tensor([1.0]):\n",
    "    num += 1\n",
    "    if reward_counter > max_reward:\n",
    "      max_reward = reward_counter\n",
    "      max_begin = begin\n",
    "      max_end = count\n",
    "    begin = count\n",
    "    reward_counter = 0\n",
    "  count += 1"
   ],
   "metadata": {
    "id": "saJmZnD94R-8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1656534490216,
     "user_tz": -330,
     "elapsed": 11,
     "user": {
      "displayName": "shreyansh jain",
      "userId": "15851526152066987878"
     }
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "action_list = []\n",
    "action_counter = max_begin + 1\n",
    "reward_counter = 0\n",
    "while action_counter <= max_end:\n",
    "  this_action = int(mario_agent.Action_Memory[action_counter].tolist()[0])\n",
    "  reward_counter += mario_agent.Reward_Memory[action_counter].tolist()[0]\n",
    "  action_list.append(this_action)\n",
    "  action_counter += 1"
   ],
   "metadata": {
    "id": "Z1uKUM1s7YoZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1656534490869,
     "user_tz": -330,
     "elapsed": 2,
     "user": {
      "displayName": "shreyansh jain",
      "userId": "15851526152066987878"
     }
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def test_model():\n",
    "    agent = mario_agent \n",
    "\n",
    "    env = gym.wrappers.Monitor(envi, \"./gym-results\", force=True)\n",
    "    env.reset()\n",
    "    state = env.reset()\n",
    "    state = torch.Tensor(np.array([state]))\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    while steps <= max_end:\n",
    "        show_state(env, max_begin)\n",
    "\n",
    "        action = action_list[steps]\n",
    "        steps += 1\n",
    "        \n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        state_next = torch.Tensor(np.array([state_next]))\n",
    "        reward = torch.tensor(np.array([reward])).unsqueeze(0)\n",
    "        terminal = torch.tensor([int(terminal)]).unsqueeze(0)            \n",
    "        state = state_next\n",
    "        if terminal:\n",
    "            break\n",
    "    print(\"Total reward after episode {} is {}\".format(max_begin + 1, total_reward))  "
   ],
   "metadata": {
    "id": "uFnKAVOJwXot",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1656534493384,
     "user_tz": -330,
     "elapsed": 586,
     "user": {
      "displayName": "shreyansh jain",
      "userId": "15851526152066987878"
     }
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "id": "OQoa3Y2SUwKm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1656534548410,
     "user_tz": -330,
     "elapsed": 51261,
     "user": {
      "displayName": "shreyansh jain",
      "userId": "15851526152066987878"
     }
    },
    "outputId": "a78e37a0-1460-4808-94b2-dfb336590058",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total reward after episode 23034 is 3069.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Exception ignored in: <function Monitor.__del__ at 0x7fa6a314a4d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitor.py\", line 226, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitor.py\", line 131, in close\n",
      "    super(Monitor, self).close()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/gym/core.py\", line 243, in close\n",
      "    return self.env.close()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/gym/core.py\", line 243, in close\n",
      "    return self.env.close()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/gym/core.py\", line 243, in close\n",
      "    return self.env.close()\n",
      "  [Previous line repeated 5 more times]\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/nes_py/nes_env.py\", line 346, in close\n",
      "    raise ValueError('env has already been closed.')\n",
      "ValueError: env has already been closed.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "#run(training_mode=False, pretrained=True)\n",
    "test_model()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VLG_Project.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}